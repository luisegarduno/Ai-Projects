{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bright-legislation",
   "metadata": {},
   "source": [
    "## Welcome to Pacman\n",
    "\n",
    "After downloading the code\n",
    "<a href=\"https://inst.eecs.berkeley.edu/~cs188/fa20/assets/files/search.zip\" target=\"_top\"> <b>(`search.zip`)</b></a>, unzipping it, and changing to the directory, you should be able to play a game of Pacman by typing the following at the command line:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocational-framing",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in Tkinter callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/blurry/anaconda3/envs/ML/lib/python3.8/tkinter/__init__.py\", line 1889, in __call__\n",
      "    try:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "%run pacman.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raised-receiver",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "--------\n",
    "\n",
    "\n",
    "Pacman lives in a shiny blue world of twisting corridors and tasty round treats. Navigating this world efficiently will be Pacman’s first step in mastering his domain.\n",
    "\n",
    "The simplest agent in `searchAgents.py` is called the `GoWestAgent`, which always goes West (a trivial reflex agent). This agent can occasionally win:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-paradise",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py --layout testMaze --pacman GoWestAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blessed-visibility",
   "metadata": {},
   "source": [
    "But, things get ugly for this agent when turning is required:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ongoing-sunglasses",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py --layout tinyMaze --pacman GoWestAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "billion-notion",
   "metadata": {},
   "source": [
    "If Pacman gets stuck, you can exit the game by typing CTRL-c into your terminal.\n",
    "\n",
    "Soon, your agent will solve not only tinyMaze, but any maze you want.\n",
    "\n",
    "Note that `pacman.py` supports a number of options that can each be expressed in a long way\n",
    "(e.g., `--layout`) or a short way (e.g., `-l`). You can see the list of all options and their default values via: %run pacman.py -h\n",
    "\n",
    "Also, all of the commands that appear in this project also appear in `commands.txt`, for\n",
    "easy copying and pasting. In UNIX/Mac OS X, you can even run all these commands in order\n",
    "with `bash commands.txt`.\n",
    "\n",
    "--------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wrong-yesterday",
   "metadata": {},
   "source": [
    "## Question 1 (3 points): Finding a Fixed Food Dot using Depth First Search\n",
    "\n",
    "In `(searchAgents.py)`, you’ll find a fully implemented `(SearchAgent)`, which plans out a path through Pacman’s world and then executes that path step-by-step. The search algorithms for formulating a plan are not implemented – that’s your job.\n",
    "\n",
    "First, test that the `(SearchAgent)` is working correctly by running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "technical-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l tinyMaze -p SearchAgent -a fn=tinyMazeSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-establishment",
   "metadata": {},
   "source": [
    "The command above tells the `(SearchAgent)` to use `(tinyMazeSearch)` as its search\n",
    "algorithm, which is implemented in `(search.py)`. Pacman should navigate the maze successfully.\n",
    "\n",
    "Now it’s time to write full-fledged generic search functions to help Pacman plan routes! Pseudocode for the search algorithms you’ll write can be found in the lecture slides. Remember that a search node must contain not only a state but also the information necessary to reconstruct the path (plan) which gets to that state.\n",
    "\n",
    "__*Important note*__: All of your search functions need to return a list of actions that\n",
    "will lead the agent from the start to the goal. These actions all have to be legal moves (valid directions, no moving through walls).\n",
    "\n",
    "__*Important note:*__ Make sure to __use__ the `(Stack)`, `(Queue)` and `(PriorityQueue)` data structures provided to you in util.py! These data structure implementations have particular\n",
    "properties which are required for compatibility with the autograder.\n",
    "\n",
    "*Hint:* Each algorithm is very similar. Algorithms for DFS, BFS, UCS, and A* differ only in the details of how the fringe is managed. So, concentrate on getting DFS right and the rest should be relatively straightforward. Indeed, one possible implementation requires only a single generic search method which is configured with an algorithm-specific queuing strategy. (Your implementation need not be of this form to receive full credit).\n",
    "\n",
    "Implement the depth-first search (DFS) algorithm in the `(depthFirstSearch)` function in\n",
    "`(search.py)`. To make your algorithm complete, write the graph search version of DFS, which avoids expanding any already visited states.\n",
    "\n",
    "Your code should quickly find a solution for:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "infectious-barrier",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l tinyMaze -p SearchAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "closed-soviet",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l mediumMaze -p SearchAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-melissa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l bigMaze -z .5 -p SearchAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "liberal-planet",
   "metadata": {},
   "source": [
    "The Pacman board will show an overlay of the states explored, and the order in which they were explored (brighter red means earlier exploration). Is the exploration order what you would have expected? Does Pacman actually go to all the explored squares on his way to the goal?\n",
    "\n",
    "Hint: If you use a (`Stack`) as your data structure, the solution found by your DFS algorithm for (`mediumMaze`) should have a length of 130 (provided you push successors onto the fringe in the order provided by getSuccessors; you might get 246 if you push them in the reverse order). Is this a least cost solution? If not, think about what depth-first search is doing wrong.\n",
    "\n",
    "Grading: Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "still-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-overall",
   "metadata": {},
   "source": [
    "--------------\n",
    "\n",
    "## Question 2 (3 points): Breadth First Search\n",
    "\n",
    "Implement the breadth-first search (BFS) algorithm in the (`breadthFirstSearch`) function in (`search.py`). Again, write a graph search algorithm that avoids expanding any already visited states. Test your code the same way you did for depth-first search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "computational-interview",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SearchAgent] using function bfs\n",
      "[SearchAgent] using problem type PositionSearchProblem\n",
      "\n",
      "Time taken for depth search sort:  24.179  milliseconds\n",
      "FINALLY?\n",
      "Path found with total cost of 68 in 0.0 seconds\n",
      "Search nodes expanded: 269\n",
      "Pacman emerges victorious! Score: 442\n",
      "Average Score: 442.0\n",
      "Scores:        442.0\n",
      "Win Rate:      1/1 (1.00)\n",
      "Record:        Win\n"
     ]
    }
   ],
   "source": [
    "%run pacman.py -l mediumMaze -p SearchAgent -a fn=bfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vanilla-slovenia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l bigMaze -p SearchAgent -a fn=bfs -z .5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surface-glucose",
   "metadata": {},
   "source": [
    "Does BFS find a least cost solution? If not, check your implementation.\n",
    "\n",
    "*Hint:* If Pacman moves too slowly for you, try the option (`--frameTime 0`).\n",
    "\n",
    "*Note:* If you’ve written your search code generically, your code should work equally well for the eight-puzzle search problem without any changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "psychological-blanket",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run eightpuzzle.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-retailer",
   "metadata": {},
   "source": [
    "*Grading:* Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imperial-knight",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "turkish-mineral",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "## Question 3 (3 points): Varying the Cost Function\n",
    "\n",
    "While BFS will find a fewest-actions path to the goal, we might want to find paths that are “best” in other senses. Consider (`mediumDottedMaze`) and (`mediumScaryMaze`).\n",
    "\n",
    "By changing the cost function, we can encourage Pacman to find different paths. For example, we can charge more for dangerous steps in ghost-ridden areas or less for steps in food-rich areas, and a rational Pacman agent should adjust its behavior in response.\n",
    "\n",
    "Implement the uniform-cost graph search algorithm in the (`uniformCostSearch`) function in (`search.py`). We encourage you to look through (`util.py`) for some data structures that may be useful in your implementation. You should now observe successful behavior in all three of the following layouts, where the agents below are all UCS agents that differ only in the cost function they use (the agents and cost functions are written for you):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l mediumMaze -p SearchAgent -a fn=ucs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l mediumDottedMaze -p StayEastSearchAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tough-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l mediumScaryMaze -p StayWestSearchAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stuffed-ethnic",
   "metadata": {},
   "source": [
    "*Note:* You should get very low and very high path costs for the (`StayEastSearchAgent`) and (`StayWestSearchAgent`) respectively, due to their exponential cost functions (see searchAgents.py for details).\n",
    "\n",
    "*Grading:* Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mobile-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "consecutive-coverage",
   "metadata": {},
   "source": [
    "------------------------\n",
    "\n",
    "## Question 4 (3 points): A* Search\n",
    "\n",
    "Implement A* graph search in the empty function (`aStarSearch`) in (`search.py`). A* takes a heuristic function as an argument. Heuristics take two arguments: a state in the search problem (the main argument), and the problem itself (for reference information). The nullHeuristic heuristic function in (`search.py`) is a trivial example.\n",
    "\n",
    "You can test your A* implementation on the original problem of finding a path through a maze\n",
    "to a fixed position using the Manhattan distance heuristic (implemented already as\n",
    "(`manhattanHeuristic`) in (`searchAgents.py`))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suffering-overhead",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l bigMaze -z .5 -p SearchAgent -a fn=astar,heuristic=manhattanHeuristic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "scenic-utilization",
   "metadata": {},
   "source": [
    "You should see that A* finds the optimal solution slightly faster than uniform cost search (about 549 vs. 620 search nodes expanded in our implementation, but ties in priority may make your numbers differ slightly). What happens on (`openMaze`) for the various search strategies?\n",
    "\n",
    "*Grading:* Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinct-deputy",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-shuttle",
   "metadata": {},
   "source": [
    "----------------------------------------\n",
    "\n",
    "## Question 5 (3 points): Finding All the Corners\n",
    "\n",
    "The real power of A* will only be apparent with a more challenging search problem. Now, it’s time to formulate a new problem and design a heuristic for it.\n",
    "\n",
    "In corner mazes, there are four dots, one in each corner. Our new search problem is to find\n",
    "the shortest path through the maze that touches all four corners (whether the maze actually\n",
    "has food there or not). Note that for some mazes like (`tinyCorners`), the shortest path\n",
    "does not always go to the closest food first! Hint: the shortest path through\n",
    "(`tinyCorners`) takes 28 steps.\n",
    "\n",
    "*Note: Make sure to complete Question 2 before working on Question 5, because Question 5\n",
    "builds upon your answer for Question 2.*\n",
    "\n",
    "Implement the (`CornersProblem`) search problem in (`searchAgents.py`). You will need to choose a state representation that encodes all the information necessary to detect whether all four corners have been reached. Now, your search agent should solve:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "laughing-spokesman",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l tinyCorners -p SearchAgent -a fn=bfs,prob=CornersProblem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-arthur",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l mediumCorners -p SearchAgent -a fn=bfs,prob=CornersProblem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "quantitative-integration",
   "metadata": {},
   "source": [
    "To receive full credit, you need to define an abstract state representation that does not encode irrelevant information (like the position of ghosts, where extra food is, etc.). In particular, do not use a Pacman (`GameState`) as a search state. Your code will be very, very slow if you do (and also wrong).\n",
    "\n",
    "*Hint 1:* The only parts of the game state you need to reference in your implementation are the starting Pacman position and the location of the four corners.\n",
    "\n",
    "*Hint 2:* When coding up (`getSuccessors`), make sure to add children to your successors list with a cost of 1.\n",
    "\n",
    "Our implementation of (`breadthFirstSearch`) expands just under 2000 search nodes on\n",
    "(`mediumCorners`). However, heuristics (used with A* search) can reduce the amount of searching required.\n",
    "\n",
    "*Grading:* Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "persistent-excess",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-twins",
   "metadata": {},
   "source": [
    "---------------------------\n",
    "\n",
    "## Question 6 (3 points): Corners Problem: Heuristic\n",
    "\n",
    "*Note: Make sure to complete Question 4 before working on Question 6, because Question 6 builds upon your answer for Question 4.*\n",
    "\n",
    "Implement a non-trivial, consistent heuristic for the (`CornersProblem`) in\n",
    "(`cornersHeuristic`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fabulous-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l mediumCorners -p AStarCornersAgent -z 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surrounded-macro",
   "metadata": {},
   "source": [
    "*Note:* (`AStarCornersAgent`) is a shortcut for `-p SearchAgent -a\n",
    "fn=aStarSearch,prob=CornersProblem,heuristic=cornersHeuristic`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-tonight",
   "metadata": {},
   "source": [
    "__*Admissibility vs. Consistency:*__ Remember, heuristics are just functions that take search states and return numbers that estimate the cost to a nearest goal. More effective heuristics will return values closer to the actual goal costs. To be admissible, the heuristic values must be lower bounds on the actual shortest path cost to the nearest goal (and non-negative). To be *consistent*, it must additionally hold that if an action has cost c, then taking that action can only cause a drop in heuristic of at most c.\n",
    "\n",
    "Remember that admissibility isn’t enough to guarantee correctness in graph search – you need the stronger condition of consistency. However, admissible heuristics are usually also consistent, especially if they are derived from problem relaxations. Therefore it is usually easiest to start out by brainstorming admissible heuristics. Once you have an admissible heuristic that works well, you can check whether it is indeed consistent, too. The only way to guarantee consistency is with a proof. However, inconsistency can often be detected by verifying that for each node you expand, its successor nodes are equal or higher in in f-value. Moreover, if UCS and A* ever return paths of different lengths, your heuristic is inconsistent. This stuff is tricky!\n",
    "\n",
    "__*Non-Trivial Heuristics:*__ The trivial heuristics are the ones that return zero everywhere (UCS) and the heuristic which computes the true completion cost. The former won’t save you any time, while the latter will timeout the autograder. You want a heuristic which reduces total compute time, though for this assignment the autograder will only check node counts (aside from enforcing a reasonable time limit).\n",
    "\n",
    "__*Grading:*__ Your heuristic must be a non-trivial non-negative consistent heuristic to receive any points. Make sure that your heuristic returns 0 at every goal state and never returns a negative value. Depending on how few nodes your heuristic expands, you’ll be graded:\n",
    "\n",
    "| Number of nodes expanded | Grade |\n",
    "---------------------------|-------|\n",
    "| more than 2000 | 0/3 |\n",
    "| at most 2000 | 1/3 |\n",
    "| at most 1600 | 2/3 |\n",
    "| at most 1200 | 3/3 |\n",
    "\n",
    "*Remember:* If your heuristic is inconsistent, you will receive no credit, so be careful!\n",
    "\n",
    "*Grading:* Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "knowing-starter",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mediterranean-point",
   "metadata": {},
   "source": [
    "------------------------------\n",
    "\n",
    "\n",
    "## Question 7 (4 points): Eating All The Dots\n",
    "\n",
    "Now we’ll solve a hard search problem: eating all the Pacman food in as few steps as\n",
    "possible. For this, we’ll need a new search problem definition which formalizes the food-\n",
    "clearing problem: (`FoodSearchProblem`) in (`searchAgents.py`) (implemented for you). A\n",
    "solution is defined to be a path that collects all of the food in the Pacman world. For the present project, solutions do not take into account any ghosts or power pellets; solutions only depend on the placement of walls, regular food and Pacman. (Of course ghosts can ruin the execution of a solution! We’ll get to that in the next project.) If you have written your general search methods correctly, (`A*`) with a null heuristic (equivalent to uniform-\n",
    "cost search) should quickly find an optimal solution to (`testSearch`) with no code change on your part (total cost of 7)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "novel-safety",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l testSearch -p AStarFoodSearchAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "detailed-designer",
   "metadata": {},
   "source": [
    "*Note:* (`AStarFoodSearchAgent`) is a shortcut for `-p SearchAgent -a fn=astar,prob=FoodSearchProblem,heuristic=foodHeuristic`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aging-breed",
   "metadata": {},
   "source": [
    "You should find that UCS starts to slow down even for the seemingly simple (`tinySearch`). As a reference, our implementation takes 2.5 seconds to find a path of length 27 after expanding 5057 search nodes.\n",
    "\n",
    "*Note: Make sure to complete Question 4 before working on Question 7, because Question 7 builds upon your answer for Question 4.*\n",
    "\n",
    "Fill in (`foodHeuristic`) in (`searchAgents.py`) with a consistent heuristic for the (`FoodSearchProblem`). Try your agent on the (`trickySearch`) board:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "parental-conversion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l trickySearch -p AStarFoodSearchAgent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-catering",
   "metadata": {},
   "source": [
    "Our UCS agent finds the optimal solution in about 13 seconds, exploring over 16,000 nodes.\n",
    "\n",
    "Any non-trivial non-negative consistent heuristic will receive 1 point. Make sure that your heuristic returns 0 at every goal state and never returns a negative value. Depending on how few nodes your heuristic expands, you’ll get additional points:\n",
    "\n",
    "| Number of nodes expanded | Grade |\n",
    "|--------------------------|-------|\n",
    "| more than 15000 | 1/4 |\n",
    "| at most 15000 | 2/4 |\n",
    "| at most 12000 | 3/4|\n",
    "| at most 9000 | 4/4 (full credit; medium) |\n",
    "| at most 7000 | 5/4 (optional extra credit; hard) |\n",
    "\n",
    "*Remember:* If your heuristic is inconsistent, you will receive no credit, so be careful! Can you solve (`mediumSearch`) in a short time? If so, we’re either very, very impressed, or your heuristic is inconsistent.\n",
    "\n",
    "*Grading:* Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-graphic",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tribal-arrangement",
   "metadata": {},
   "source": [
    "-------------------------------\n",
    "\n",
    "\n",
    "## Question 8 (3 points): Suboptimal Search\n",
    "\n",
    "\n",
    "Sometimes, even with A* and a good heuristic, finding the optimal path through all the dots is hard. In these cases, we’d still like to find a reasonably good path, quickly. In this section, you’ll write an agent that always greedily eats the closest dot. (`ClosestDotSearchAgent`) is implemented for you in (`searchAgents.py`), but it’s missing a key function that finds a path to the closest dot.\n",
    "\n",
    "Implement the function (`findPathToClosestDot`) in (`searchAgents.py`). Our agent solves this maze (suboptimally!) in under a second with a path cost of 350:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "verbal-surgery",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run pacman.py -l bigSearch -p ClosestDotSearchAgent -z .5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "civic-minimum",
   "metadata": {},
   "source": [
    "\n",
    "*Hint:* The quickest way to complete (`findPathToClosestDot`) is to fill in the\n",
    "(`AnyFoodSearchProblem`), which is missing its goal test. Then, solve that problem with an appropriate search function. The solution should be very short!\n",
    "\n",
    "Your (`ClosestDotSearchAgent`) won’t always find the shortest possible path through the maze. Make sure you understand why and try to come up with a small example where repeatedly going to the closest dot does not result in finding the shortest path for eating all the dots.\n",
    "\n",
    "Grading: Please run the below command to see if your implementation passes all the autograder test cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-fashion",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run autograder.py -q q8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "announced-reverse",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
